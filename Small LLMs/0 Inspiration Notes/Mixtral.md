Mixtral is a Mixture of Expert LLM, which outperforms Llama 2 70B on most benchmarks with 6x faster inference.

**Organizations:** [MistralAI](https://mistral.ai)
## SPEC:
- Sub-versions: 
- Max tokens: 32K
- Languages: en, fr, it, ge, sp
- Ranking: 
	- HF Arena rank: 7 for Mixtral 8x7B-Instruct
	- HF Score: 68.47 Mixtral-8x7B-v01
	- Open Router: 9 for Mistral 7B-Instruct
## LICENSE: 
- Apache 2.0
## Descendent:
- 
## Links:
- 

2024-01-22

#mistral_family #MoE