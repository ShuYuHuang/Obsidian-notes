Vicuna project was hosted by Stanford, using LLAMA models to build open accessible and scalable LLMs. For Vicuna 1.5, they used GPT4 as judge to do RLHF in instruction tuning stage.
**Organizations:** UC Berkeley, UC San Diego, Carnegie Mellon University, Stanford, MBZUAI
## SPEC
- Sub-versions: 7B, 13B, 33B - instruction/ complete
- Max tokens: 4K, 16K
- Rankings
	- Arena Rank: 17 for Vicuna 33B
	- HF score: [54.97](https://huggingface.co/lmsys/vicuna-13b-v1.5-16k)
## LICENSE: 
- Ok for commercial use
- Need to supply with notice page
- [Llama 2 Community License Agreement - Meta AI](https://ai.meta.com/llama/license/)
## Links
- [Vicuna and LMSYS](https://huggingface.co/lmsys)
- [2306.05685.pdf (arxiv.org)](https://arxiv.org/pdf/2306.05685.pdf)

#llama_family #MBZAI
