Vicuna project was hosted by Stanford, using LLAMA models to build open accessible and scalable LLMs. For Vicuna 1.5, they used GPT4 as judge to do RLHF in instruction tuing stage.
**Organizations:** UC Berkeley, UC San Diego, Carnegie Mellon University, Stanford, MBZUAI
## SPEC
- Sub-versions: 7B, 13B, 33B - chat, complete
- Max tokens: 4K, 16K
- HF score: [54.97](https://huggingface.co/lmsys/vicuna-13b-v1.5-16k)
## LICENSE: 
- Ok for commertial use
- Need to supply with notice page
- [Llama 2 Community License Agreement - Meta AI](https://ai.meta.com/llama/license/)
## Links
[Vicuna and LMSYS](https://huggingface.co/lmsys)
[2306.05685.pdf (arxiv.org)](https://arxiv.org/pdf/2306.05685.pdf)